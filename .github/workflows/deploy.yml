name: Deploy to Production

on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      version:
        description: 'Version to deploy'
        required: false
        type: string

env:
  REGISTRY: ghcr.io
  IMAGE_NAME_BACKEND: ${{ github.repository }}/backend
  IMAGE_NAME_FRONTEND: ${{ github.repository }}/frontend

jobs:
  # Build and Push Docker Images
  build-and-push:
    name: Build and Push Images
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    outputs:
      backend-image: ${{ steps.meta-backend.outputs.tags }}
      frontend-image: ${{ steps.meta-frontend.outputs.tags }}
      version: ${{ steps.meta-backend.outputs.version }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract backend metadata
      id: meta-backend
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_BACKEND }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Extract frontend metadata
      id: meta-frontend
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_FRONTEND }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push backend image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile
        push: true
        tags: ${{ steps.meta-backend.outputs.tags }}
        labels: ${{ steps.meta-backend.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64,linux/arm64

    - name: Build and push frontend image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./frontend/Dockerfile
        push: true
        tags: ${{ steps.meta-frontend.outputs.tags }}
        labels: ${{ steps.meta-frontend.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64,linux/arm64

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_BACKEND }}:latest
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  # Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: build-and-push
    if: github.ref == 'refs/heads/main' || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'staging')
    environment:
      name: staging
      url: https://staging.optimus.example.com
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name ${{ secrets.EKS_CLUSTER_NAME_STAGING }}

    - name: Deploy to staging
      run: |
        # Update image tags in Kubernetes manifests
        sed -i "s|optimus/backend:latest|${{ needs.build-and-push.outputs.backend-image }}|g" k8s/overlays/staging/kustomization.yaml
        sed -i "s|optimus/frontend:latest|${{ needs.build-and-push.outputs.frontend-image }}|g" k8s/overlays/staging/kustomization.yaml
        
        # Apply Kubernetes manifests
        kubectl apply -k k8s/overlays/staging/
        
        # Wait for rollout to complete
        kubectl rollout status deployment/optimus-backend -n optimus-staging --timeout=300s
        kubectl rollout status deployment/optimus-frontend -n optimus-staging --timeout=300s

    - name: Run smoke tests
      run: |
        # Wait for services to be ready
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=optimus -n optimus-staging --timeout=300s
        
        # Get service endpoint
        BACKEND_URL=$(kubectl get ingress optimus-ingress -n optimus-staging -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
        
        # Run smoke tests
        curl -f "https://${BACKEND_URL}/health" || exit 1
        curl -f "https://${BACKEND_URL}/api/health" || exit 1

    - name: Notify deployment status
      uses: 8398a7/action-slack@v3
      if: always()
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        fields: repo,message,commit,author,action,eventName,ref,workflow
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

  # Deploy to Production
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [build-and-push, deploy-staging]
    if: startsWith(github.ref, 'refs/tags/') || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'production')
    environment:
      name: production
      url: https://optimus.example.com
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name ${{ secrets.EKS_CLUSTER_NAME_PROD }}

    - name: Create deployment backup
      run: |
        # Backup current deployment
        kubectl get deployment optimus-backend -n optimus-prod -o yaml > backup-backend-deployment.yaml
        kubectl get deployment optimus-frontend -n optimus-prod -o yaml > backup-frontend-deployment.yaml

    - name: Deploy to production
      run: |
        # Update image tags in Kubernetes manifests
        sed -i "s|optimus/backend:latest|${{ needs.build-and-push.outputs.backend-image }}|g" k8s/overlays/prod/kustomization.yaml
        sed -i "s|optimus/frontend:latest|${{ needs.build-and-push.outputs.frontend-image }}|g" k8s/overlays/prod/kustomization.yaml
        
        # Apply Kubernetes manifests
        kubectl apply -k k8s/overlays/prod/
        
        # Wait for rollout to complete
        kubectl rollout status deployment/optimus-backend -n optimus-prod --timeout=600s
        kubectl rollout status deployment/optimus-frontend -n optimus-prod --timeout=600s

    - name: Run production health checks
      run: |
        # Wait for services to be ready
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=optimus -n optimus-prod --timeout=600s
        
        # Get service endpoint
        BACKEND_URL=$(kubectl get ingress optimus-ingress -n optimus-prod -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
        
        # Comprehensive health checks
        curl -f "https://${BACKEND_URL}/health" || exit 1
        curl -f "https://${BACKEND_URL}/api/health" || exit 1
        curl -f "https://${BACKEND_URL}/api/projects" || exit 1

    - name: Run database migrations
      run: |
        # Run database migrations in production
        kubectl exec -it deployment/optimus-backend -n optimus-prod -- alembic upgrade head

    - name: Update production monitoring
      run: |
        # Update monitoring dashboards
        kubectl apply -f monitoring/production/

    - name: Create release
      if: startsWith(github.ref, 'refs/tags/')
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: Release ${{ github.ref }}
        draft: false
        prerelease: false
        body: |
          ## Changes in this Release
          - Backend Image: ${{ needs.build-and-push.outputs.backend-image }}
          - Frontend Image: ${{ needs.build-and-push.outputs.frontend-image }}
          
          ## Deployment Information
          - Deployed to production at: ${{ steps.deployment.outputs.timestamp }}
          - Environment: Production
          - Cluster: ${{ secrets.EKS_CLUSTER_NAME_PROD }}

    - name: Notify production deployment
      uses: 8398a7/action-slack@v3
      if: always()
      with:
        status: ${{ job.status }}
        channel: '#production'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        fields: repo,message,commit,author,action,eventName,ref,workflow
        custom_payload: |
          {
            attachments: [{
              color: '${{ job.status }}' === 'success' ? 'good' : 'danger',
              fields: [{
                title: 'Production Deployment',
                value: '${{ job.status }}' === 'success' ? '✅ Successfully deployed to production' : '❌ Production deployment failed',
                short: true
              }, {
                title: 'Version',
                value: '${{ needs.build-and-push.outputs.version }}',
                short: true
              }]
            }]
          }

  # Rollback on Failure
  rollback:
    name: Rollback on Failure
    runs-on: ubuntu-latest
    if: failure() && needs.deploy-production.result == 'failure'
    needs: [deploy-production]
    environment:
      name: production
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name ${{ secrets.EKS_CLUSTER_NAME_PROD }}

    - name: Rollback production deployment
      run: |
        # Rollback to previous deployment
        kubectl rollout undo deployment/optimus-backend -n optimus-prod
        kubectl rollout undo deployment/optimus-frontend -n optimus-prod
        
        # Wait for rollback to complete
        kubectl rollout status deployment/optimus-backend -n optimus-prod --timeout=300s
        kubectl rollout status deployment/optimus-frontend -n optimus-prod --timeout=300s

    - name: Verify rollback
      run: |
        # Verify services are healthy after rollback
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=optimus -n optimus-prod --timeout=300s
        
        # Test endpoints
        BACKEND_URL=$(kubectl get ingress optimus-ingress -n optimus-prod -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
        curl -f "https://${BACKEND_URL}/health" || exit 1

    - name: Notify rollback
      uses: 8398a7/action-slack@v3
      with:
        status: 'warning'
        channel: '#production'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        fields: repo,message,commit,author,action,eventName,ref,workflow
        custom_payload: |
          {
            attachments: [{
              color: 'warning',
              fields: [{
                title: 'Production Rollback',
                value: '⚠️  Production deployment failed and was rolled back',
                short: false
              }]
            }]
          }